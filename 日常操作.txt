测试环境：田雨   开发环境：盛浩然

1.将文件传入容器云数据库，使用scp命令不行，需要使用ansible，具体指令如下：
ansible all -i t.txt -m copy -a "src=tree.sh dest=/tmp/"

t.txt 存放的是 用户名@域名 例如 root@monitor-zabbix.mysql.svc.cs1-ly.hpc
src   存放的需要传输的文件
dest  存放的是 目标路径

1.1 想把容器上的文件传到50跳板机
scp filename test@192.168.157.50:/tmp     密码：test

2.1)使用scp从物理机上传文件到50跳板机
在50跳板机上执行：scp -r 目标主机IP:文件所在目录 50跳板机上目录
2) 从50跳板机


2.登录容器云数据库
登录主机：ssh root@域名
登录数据库：mysql-root mydb


远程连接数据库：使用inception用户 注意密码需要添加单引号
mysql -u'inception' -p'password' -h opensp.zjjpt-lycore.svc.cs1-ly.hpc -P 20035

相当于 show full processlist;
select user,db,command,state,max(time),count(*) from information_schema.processlist where command != 'Sleep' and user not in ('system user', 'replic') group by user,command,state,db order by max(time),count(*) desc;

3.通过ucp用户登录通信云主机
1)跳板机50上执行： ssh ucp@192.168.151.64
2)sh ssh 省份简称  
3)sudo su - zx
4)登录具体ip
5)切root: sudo su -    
		root密码：()OP90op  90op()OP
		su - root    输入root密码
4.通信云资源纳入：
1)通信云实例信息、数据库信息，统一由数据库侧进行管理纳入
2)通信云新建数据库统一走研发云--数据库新建流程申请，申请工单中明确申请数据库名称及对应工程信息
3)通信云侧配合将原有CMDB中不规范或错误信息进行调整修改，后续管理交由数据库进行统一操作

5.应用的配置文件中写core域名，core域名cname解析到咱们容器的hpc域名
core域名需要向域名管理员申请,走研发云，域名管理流程
规范的业务本身已经有core域名,没有core域名属于不规范，进行补充申请
那core域名谁来负责申请？ 业务侧
现在迁移流程：
1)通知业务迁移事项，让业务对我们进行配合
2)梳理要迁移的目标，将要迁移的目标梳理，填写到迁移列表
3)业务按照列表反馈信息
4)同步创建容器集群，进行容器与物理机复制关系的搭建
5)业务进行割接，按照SOP文档进行操作

6.登录研发云账号
不能同时在一个浏览器中登录两个账户，否则会串号，工单没有办法执行的

7.每个省全量前，都需要检查优化邮件
1)大表
2)测试有无主键
3)查看慢日志，是否有可优化的慢SQL

8.密码延期
如果主机已经纳入到4A，可以找安全组的贾鑫将Mysql用户托管到4A，以后都不用延期了
如果主机暂时无法纳入4A，可以使用ucp用户登上主机，再sudo su - 切换到root用户，
使用 chage -l mysql 查看mysql用户密码过期时间，直接passwd mysql，输入新的密码，
就自动延期成功了

9.新建数据库工单时，如果数据库名称书写错误，最好重新提一个工单，
如果只是在中途意见中添加修改意见，CMDB可能会录入错误，比较麻烦

10.授权数据库用户
grant all privileges on *.* to nxr@'%' identified by '123';

grant select,insert,delete,update on test.* to ucp_rtc@'%'
 identified by 'Edk^xsynCY2CKpR';

flush privileges;


devops_db/Yhn97Y6rQAZ!PUax


授予权限
grant all privileges on hive.* to 'hive'@'%';
grant super on ambari.* to 'ambari'@'%';
grant select on *.* to 'csap'@'%' identified by 'qXliH9*Ro#qDGomY';
创建用户
create user 'hive'@'%' identified by 'D5CY0G4JVPAUWIbs';
回收权限
revoke create on contrans.* to 'contract'@'%';

revoke insert,delete,update on *.* from ucp_rtc@'%';

修改用户密码
alter user 'ngwf_rosk'@'%' identified by 'PYANFOix0I#m';



12. Threads_running: (并发连接数)正在执行查询的线程数 Queries: 每秒查询数 
	Threads_connected: 数据库连接
mysqladmin -uroot -p -S mysql.sock ext -i1|awk '/Queries/{q=$4-qp;qp=$4}/Threads_connected/{tc=$4}/Threads_running/{printf "%5d %5d %5d\n", q, tc, $4}'

13. 宿主机重启演练
采取滚动重启的方式重启数据库主机，主机重启顺序：
太原机房：
1.10.231.254.23
2.10.231.254.24
侯马机房：
3.10.231.253.24
4.10.231.253.23
5.10.231.253.76
6.10.231.253.75
重启主机前先通知下我，等我把数据库服务停了再进行主机重启。



14.通信云容灾中心演练
需要将主中心的VIP换成备中心的VIP，修改同步链路
一、容灾库切换成生产环境
ssh gsm_135.130.19.162
1.生产库read_only=on打开，并kill连接；容灾库read_only=off关闭
cd /home/mysql/shell
sh set_read_only_kill.sh 135.130.19.162 20002

ssh  gsm_135.130.19.162
stop slave;
change master to master_host = '10.136.217.50',  master_port=20002,master_auto_position = 1;
start slave;

登录容灾库
ssh gsm_135.130.21.39
set global read_only=off
做完上面的再让业务方进行业务切换




二、生产库再次还原
ssh gsm_135.130.21.39

1.容灾库read_only=on打开，并kill连接；生产库read_only=off关闭
cd /home/mysql/shell
sh set_read_only_kill.sh 135.130.21.39 20002

ssh gxm_135.130.19.162
stop slave;
change master to master_host = '135.130.19.155',  master_port=20002,master_auto_position = 1;
start slave;

登录生产库
ssh gsm_135.130.19.162
set global read_only=off

故障处理
提前检查了主中心和备中心的Executed_GTID_set，发现生产库，备库GTID不一致，原因是备库之前写入操作。解决方法：
针对备库，1) stop slave; 
2) reset master;
3) set @@GLOBAL.GTID_PURGED=''; # GTID复制同生产库一样 
4) start slave; 
原则上主库不能执行reset master;只能在备库执行reset master重新设定GTID通生产库一致。这个需要保证生产库已经把read_only打开，不会有写入，GTID也不会有变化。
容灾中心的两个库都需要reset master,设置成同生产库一致就行。

15. 主备延时的来源
	  (1) 主库DML语句并发大，从库qps高
	  主库提供了写能力，那么备库可以提供一些读能力。或者一些运营后台需要的分析语句,备库上的查询耗费了大量的 CPU 资源，影响了同步速度，造成主备延迟。
	  处理意见：一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力，控制并发

	  show full processlist;
	  show master status;                                   查看mysql正在使用的日志文件
	  show binlog events in 'mysql-bin.000003';             日志内容查看
	  mysqlbinlog --base64-output=decode-rows -vvv --start-datetime='2021-04-21 11:40:00' --stop-datetime='2021-04-21 11:49:00' mysql-bin.000001    日志内容详细查看

	  (2)大事务。
	  因为主库上必须等事务执行完成才会写入 binlog，再传给备库。如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10分钟。
	  处理意见：1)一次性地用 delete 语句删除太多数据，
	              要控制每个事务删除的数据量，分成多次删除。
	            2)大表 DDL
	  			  对于online DDL来说，扫描原表数据和构建临时文件，很消耗IO和CPU资源

	  select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60;
处理意见：
	通过show engine innodb status\G,  查看




测试有无主键
select table_schema,table_name from information_schema.tables 
where (table_schema,table_name) not in(
    select distinct table_schema,table_name from information_schema.columns where COLUMN_KEY='PRI'    
) and table_schema not in ('sys','mysql','information_schema','performance_schema');

测试外键是否已经存在
SELECT * FROM information_schema.KEY_COLUMN_USAGE WHERE CONSTRAINT_NAME='FK_PRODUCT_ID';

测试大表
select table_schema,table_name,table_rows from information_schema.tables where table_schema not in('information_schema','mysql','performance_schema','sys','zxdba_bak') and table_rows>10000 order by table_rows desc;

测试触发器
select * from information_schema.triggers where trigger_schema not in ('sys','mysql','information_schema','performance_schema')\G

测试存储过程
select * from information_schema.triggers where trigger_schema not in ('sys','mysql','information_schema','performance_schema')\G

16.mysql主从同步报错，提示Last_Error: Coordinator stopped because there were error(s) in the worker(s). The most recent failure being: Worker 1 failed executing transaction

(1) 登录从库，看一下mysql的error日志
(2) show slave status \G  根据提示查询报错的信息，得到相对应的binlog,position
(3) select * from performance_schema.replication_applier_status_by_worker\G
	可以查询到异常数据出现在哪个库和表
(4) 进入主库，去对应的binlog日志去查询数据库操作记录,通过position号定位误操作
	mysqlbinlog --base64-output=decode-rows -vvv /data/mysql/db_5721/mysql-bin.000002;
(5) 主从数据库数据一致化
(6) 从库中
	注入空事务
	STOP SLAVE;
	SET @@SESSION.GTID_NEXT = '8fc8d9ac-a62b-11e6-a3ee-a4badb1b4a00:7649';
	BEGIN; COMMIT;
	SET @@SESSION.GTID_NEXT = AUTOMATIC;  
	START SLAVE;
利用XBK恢复数据
XBK全备
1.备份方式
	（1）对于非Innodb表（比如 myisam）是，锁表cp数据文件，属于一种温备份。
	（2）对于Innodb的表（支持事务的），不锁表，拷贝数据页，最终以数据文件的方式保存下来，把一部分redo和undo一并备走，属于热备方式
2.XBK在innodb表备份恢复的流程
	（1）XBK备份执行的瞬间，立即出发ckpt，已提交的数据脏页，从内存刷写到磁盘，
		 并记录此时的LSN(日志序列号)号
	（2）备份时，拷贝磁盘数据页，并且记录备份过程中产生的redo和undo一起拷贝走，
		 也就是checkpoint LSN 之后的日志，记录此时的LSN
	（3）在恢复之前，模拟innodb 自动故障恢复 的过程，将redo(前滚)与undo(回滚)进行应用
	（4）恢复过程是cp 备份到数据目录

示例：
(1) 通过xbk物理备份主库，进入/opt5目录下，
	innobackupex --defaults-file=/data/mysql/db_3311/conf/3311.cnf --socket=/data/mysql/db_3311/mysql.sock --port=3311 -uroot -p'' /data/mysql/db_3311/ 
(2) 将redo进行重做，已提交的写到数据文件，未提交的使用undo回滚掉。模拟了CSR的过程
	innobackupex --apply-log  /data/mysql/backup/2019-10-16_18-27-58
(3) 通过scp命令，将备份文件传到另外一个主机上的备库
	scp -r 2019-10-16_18-27-58 192.168.157.51:/data/mysql/db_5721
(4) 停掉从库的Mysql实例，清空/data /ulog /rlog 目录，保证数据目录下是空的
	rm -rf data/
	rm ulog/*
	rm rlog/*
(4) 开始恢复数据
	innobackupex --defaults-file=/data/mysql/conf/5721.cnf --copy-back
	             /data/mysql/backup/2019-10-16_18-27-58
(5) 通过ps -ef|grep mysqld 查看启动文件,启动mysqld服务
	/usr/local/mysql/bin/mysqld --defaults-file=/data/mysql/db_nxr1/conf/nxr1.cnf --basedir=/usr/local/mysql --datadir=/data/mysql/db_nxr1/data --log-error=/data/mysql/db_nxr1/elog/mysql.err --open-files-limit=65000 --pid-file=/data/mysql/db_nxr1/mysql.pid --socket=/data/mysql/db_nxr1/mysql.sock --port=3310 &
(6) mysql -uroot -p123456 -S mysql.sock

15.搭建新从库，双主

grant replication slave,replication client on *.* to 'replic'@'%' identified by '4%REplic';

从库：
stop slave;
reset master;
reset slave all;
set @@GLOBAL.GTID_PURGED=' ';    备份文件中xtrabackup_info中GTID信息
change master to master_host='192.168.157.51', MASTER_PORT=6000, master_user='replic', master_password='4%REplic', MASTER_AUTO_POSITION=1;
start slave;
show slave status\G


16.select user,db,command,state,max(time),count(*) from information_schema.processlist where command != 'Sleep' and user not in ('system user', 'replic', 'root') group by user,db,command,state
 order by max(time),count(*) desc;
 



17.批量脚本 rename表
SELECT
    CONCAT(
        'kill ',
        id,
        ';'
    )
FROM
    information_schema.processlist
WHERE
   
rename
select concat('alter table ',table_schema,'.',table_name,' to zxdba_bak.',table_schema,'_',table_name,';') from information_schema.tables where table_schema = '';
rollback
select concat('alter table zxdba_bak.',table_schema,'_',table_name','to ',table_schema,'.',table_name,';') from information_schema.tables where table_schema = '';

source /tmp/nxr.sql   不需要给路径加单引号，不然会报Fail to open file....

18.行锁---查看是哪个线程占着这个写锁，可以通过sys.innodb_lock_waits表查到。

select p.user, p.db, p.host, l.lock_table, l.lock_data from information_schema.innodb_locks as l, information_schema.innodb_trx as t, information_schema.processlist as p where l.lock_trx_id = t.trx_id and t.trx_mysql_thread_id = p.id;

-- 当前运行的所有事务
select *  from information_schema.innodb_trx;
-- 当前出现的锁
SELECT * FROM information_schema.INNODB_LOCKS;
-- 锁等待的对应关系
select *  from information_schema.INNODB_LOCK_WAITS;



19.MDL-----show full prcesslist; Waiting for table metadata lock 状态
1) select * from performance_schema.metadata_locks;  查看谁持有该表的MDL，owner_thread_id 线程ID
2) select * from performance_schema.threads where thread_id = 1中查到的id ; 得到processlist_id
3) kill processlist_id


这时我们可能需要performance_schema库下的四张表metadata_locks、threads、events_statements_current及events_statements_history。events_statements_current记录了所有在线session执行的最后一条语句
events_statements_history记录了所有在线session执行语句的历史记录（默认每个session记录10条数据，由全局参数performance_schema_events_statements_history_size决定，如果session下线则相关记录会自动被删除）
threads表用来关联processlist_id及thread_id
metadata_locks表记录了元数据锁的信息

如果查询结果为空，
update performance_schema.setup_instruments set ENABLED='YES',TIMED='YES' where name='wait/lock/metadata/sql/mdl';
select blocking_pid from sys.schema_table_lock_waits;
可以找到造成阻塞的process id，把这个连接有kill 命令断开即可

20.数据库表结构及数据迁移

1) mysqldump 方法 ---可以通过where参数增加过滤条件，来导出部分条件，但是不能使用join这种比较复杂的where
条件写法
mysqldump --skip-add-drop-table --set-gtid-purged=OFF --single-transaction --add-locks=0 ngbusi_sh  func_busi_log_202008 old_function -S mysql.sock -uroot -p''  --result-file=/data/mysql/db_ngpm-container/nxr.sql

注意在source脚本时，首先use 所选数据库
在容器中执行脚本时，需要上传到容器数据库所在主机，否则可能会出现Access denied之类的错误，
因为inception用户的权限不够，需要root权限

2) 导出csv文件 ---支持所有的SQL写法。但是每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份

将查询结果导出到服务端本地目录：
select * from db.t where id<999 into outfile '/tmp/nxr.csv';

into outfile 指定了文件的生成位置（/server_tmp/），这个位置必须受参数 secure_file_priv 的限制。参数 secure_file_priv 的可选值和作用分别是：
	如果设置为 empty，表示不限制文件生成的位置，这是不安全的设置；
	如果设置为一个表示路径的字符串，就要求生成的文件只能放在这个指定的目录，或者它的子目录；
	如果设置为 NULL，就表示禁止在这个 MySQL 实例上执行 select … into outfile 操作。
容器云数据库目录在 /data/mysql/db_tjz/tmp

得到.csv导出文件后，你就可以用下面的load data命令将数据导入到目标表db.t1中：
load data infile '/tmp/nxr.csv' into table db.t1;

select ... into outfile 方法不会生成表结构文件，可以使用mysqldump 提供一个参数 --tab，
可以同时导出表结构定义文件和csv文件。
mysqldump --skip-add-drop-table --set-gtid-purged=OFF --single-transaction --add-locks=0 --where=
'id<999' -S /data/mysql/db_mddc/mysql.sock -uroot -p'' nxr words --tab=/data/mysql/db_tjz/tmp
会在tmp目录下生成words.sql保存建表语句，words.txt保存CSV文件

3)如果没有办法使用select... into outfile，直接将SQL执行的结果重定向到文件中

mysql -uuser -ppasswd -S mysql.sock -Ne "use nxr;select * from words;" > /tmp/nxr.txt

mysql -uuser -ppasswd -S mysql.sock -N <nxr.sql > /tmp/nxr.txt
nxr.sql是具体的SQL语句

4)物理拷贝 ---- 必须全表拷贝，需要登录服务器上拷贝数据，必须是InnoDB引擎
在Mysql 5.6版本引入了可传输表空间(transportable tablespace)的方法，可以通过导入+导出表空间的方式，
实现物理拷贝表的功能

假设在db库下，复制一个跟表t相同的表r，具体的执行步骤如下：
1.create table r like t;               创建一个相同表结构的空表
2.alter table r discard tablespace;    r.ibd文件会被删除
3.flush table t for export;            db目录下会生成t.cfg，t表处于只读状态
4.cp t.cfg r.cfg    cp t.ibd r.ibd     拷贝得到的两个文件，Mysql进程要有读写权限
5.unlock tables;                       t.cfg文件会被删除
6.alter table r import tablespace      将r.ibd文件作为表r的新的表空间，表r和表t相同的数据

12.双中心同步
提前做的准备：
1)资源管理 --> 实例管理 点击新增
实例名字：统一知识库ngkm-洛阳-容器    接触记录ngcct-洛阳-容器    服务请求ngwf_yn-洛阳-容器
归属地：洛阳
真实ip地址：ngkm.mysql.svc.cs1-ly.hpc:20005
访问地址：ngkm.mysql.svc.cs1-ly.hpc:20005
点击验证，保存
2)资源管理 --> 业务库管理 点击新增
归属业务：在同步任务中输入同步任务名称(也就是数据库名称)查找其归属业务
所属实例：选择新增的实例名，通常在下拉框的最后
选择业务库：将需要同步的数据库选中

3)同步任务---> 通过同步任务名称 查询
1.点击禁用，同步进度中的gtid信息复制到文件中
2.将所有的正则表达式都去掉，将已配置的表和正则表达式导出，将已选择数据表往左表移动，点击保存

ngosc_z-淮安-容器

mysqldump时执行超时，可以临时将max_execution_time调大，默认10s(10000毫秒)，执行完再恢复成默认值
show variables like 'max_execution_time'; 
set global max_execution_time = 1000000;


13.如何大批量删除数据，比如删除前10000的订单

分批删除，每次删除之间停顿一会儿
在一个连接中循环执行20次delete from T limit 500

15.如果出现无主键表一次删除大量数据，导致出现很大的主备延时
可以先用show engine innodb status\G  查看该事务已经删除了多少行undo log entries
1) 如果比较少的话，可以选择
kill thread_id
stop slave
set sql_log_bin=0
手动执行delete语句   有可能需要关闭安全模式 set 
set sql_log_bin= 1
start slave;
show slave status\G  会有报错，如果是5.7，直接跳过报错的GTID, 如果是5.6，可以解析待执行的relay日志
                     根据报错的position
                  mysqlbinlog --base64-output=decode-rows -vvv --stop-position=767887 relay.000002;   
找到报错的GTID，通过注入空事务的方式跳过他



14.登录中间件数据库执行数据库工单

远程登录    mysql -uroot -p -h IP -P port -N <nxr.sql>/tmp/nxr.txt


15.tree_spkf.sh这个是通过show processlist 查看备库连接，  优点是比较准确，缺点无法获得端口号；
tree.sh 使用的是 show slave hosts， 优点是能够直接拿到从库的ip和port，缺点就是依赖从库的参数配置，
show variables like '%report%'; 需要在从库的参数文件中指定report_host, report_port

select * from mysql.slave_master_info\G
查看复制用户和密码


16.关闭二进制日志
set sql_log_bin=0


18.
一、进行容器内外复制同步关系搭建已有脚本，脚本在157.50 :/home/mysql/zhanggr/python/qianyi/qianyi.py
二、操作方法
1）加载python依赖  source /home/mysql/py_venv/fab_venv/bin/activate
2)  按配置文件格式填写配置文件，要求每个实例一行，仅需4个参数
3）执行脚本 python qianyi.py
三、这是迁移脚本的配置文件格式。
省份简写(ly,ha),容器集群名,迁移目标ip,迁移目标端口
---------------------------------------------------------------
迁移脚本修复了个小bug，实例名显示不准确的。最新脚本在/home/mysql/zhanggr/python/qianyi/qianyi.py

注意，新迁移脚本增加了中心标识，不单是原来的ly和ha了，新增了一个ha-arm，针对淮安arm集群
nohup python qianyi.py &



一、自动跳过报错事务，并解析记录报错GTID的binlog日志，脚本在157.50 /home/mysql/nxr/replaction_recovery/repl-recovery.py
二、操作方法
1）加载python依赖  source /home/mysql/py_venv/fab_venv/bin/activate
2）按配置文件中格式填写配置文件，仅需3个参数
3）执行脚本 python repl-recovery.py
三、这是脚本的配置文件格式。
主机类型 ,容器集群名, 端口
示例：docker, nxr-test.mysql.svc.ly.hpc, 20001
	  vm, 182.168.157.20, 20001

一、分公司主机批量添加免密，脚本在/home/mysql/nxr/batch_add_public_key/batch_key.py
二、操作方法
1) 加载python依赖  source /home/mysql/py_venv/fab_venv/bin/activate
2) 填写两个配置文件信息，public_key.txt 为存放主机公钥的文件
host_info.txt 是存放具体省份和IP信息
3) 执行脚本 python batch_key.py
三、这是host_info.txt 脚本的配置文件格式。
province: 省份名
ip:
下面写具体的ip信息



19. 192.168.157.50 ----->   jxm_10.182.48.184
1) 当前主机目录下使用 .ssh/ssh-keygen 
----生成私钥当前目录下.ssh/id_rsa
----生成公钥          .ssh/id_rsa.pub
2) 将公钥传给目标主机中 .ssh/authorized_keys


迁移实例时创建用户
create user 'manu_db_agent'@'%' identified by '05hyUCI1Wps1Kwtd';
grant select, process, super on *.* to 'manu_db_agent'@'%';

查看/data目录下面，最大的几个文件
du -csh * | sort -rh | head


在驱逐和升级后，点击添加/删除CMDB信息时，发现POD信息会及时被更新，而集群信息需要等几分钟才会更新，所以
经常会出现集群下面没有挂接任何东西的情况。

drop user operator'%';
set password for operator'192.168.207.%' = password('123456')
create user 'healthchecker'@'localhost' identified by 'healthcheckpass';

添加同步表时，由于表的数量过多，可以检查正则表达式是否匹配了所有的表，如果没有，可以先把所有同步的表先移到左边，再添加正则同步表


查看业务应用是否通过VIP连接数据库
netstat -an |grep 20002
左边是本机IP或VIP 右边是业务IP


50跳板机上
sh shell/oslogin.sh
填sh
ssh zx@10.10.228.249/250
密码：zx

一键化新建实例脚本 /home/mysql/nxr/dbsys_install.tar.gz
1) 通过zx用户将该文件scp上传到待搭建的主机/tmp目录下
	先将文件上传至 dbops@172.20.4.61
	后面在61跳板机上再将文件上传至目标主机249/250
2) 切换到root用户 sudo su -  
3) 解压dbsys_install.tar.gz
执行avoid_passwd.sh脚本，建mysql用户，实现免密登录
chown -R mysql:mysql dbsys_install
4) 编辑dbsys_install.sh脚本该脚本，根据实例情况填写
mysql_service_id 主库(端口+01) 从库(端口+02)
buffer_size  主机内存的一半
interface 可以通过ip addr查看网卡名字
ldir 将脚本传到/tmp目录下就行
5) 修改好脚本后，直接sh dbsys_install.sh 就行，会自动搭建实例，脚本执行完后
6) 根据1008611入网规范，检查实例是否成功搭建
7) 新建实例搭主从
主库：
stop slave;
reset master; 
reset slave all;
change master to master_host='172.19.106.216', MASTER_PORT=20031, master_user='replic', master_password='4%REplic', MASTER_AUTO_POSITION=1;
从库：
reset master; 
reset slave all;
change master to master_host='172.19.106.78', MASTER_PORT=20031, master_user='replic', master_password='4%REplic', MASTER_AUTO_POSITION=1;
8) 分别登录主从库，启动slave
start slave;
show slave status\G


mysql连接报“Communications link failure”错误

wait_timeout是非交互式连接的空闲超时，interactive_timeout是交互式连接的空闲超时。执行时间不计入空闲时间。这两个超时设置得是否一样要看情况。
autoReconnect=true testOnBorrow=True


主机系统日志 /var/log/messages    keepalived日志可能会存在这里面

1.先把从库的keepalived停了，将日志输出到keepalived日志
sudo systemctl stop keepalived
vim /etc/rsyslog.conf 添加一行 local0.* /usr/local/keepalived/log/keepalived.log
sudo sytemctl restart rsyslog

2.然后主库的keepalived停了，将日志输出到keepalived日志
sudo systemctl stop keepalived
vim /etc/rsyslog.conf 添加一行 local0.* /usr/local/keepalived/log/keepalived.log
sudo sytemctl restart rsyslog
3. 拉起主库的keepalived 
sudo systemctl start keepalived
4.拉起从库的keepalived
sudo systemctl start keepalived


以用户功能为索引的服务和资源的全视图。首先，我们需要一个系统来记录前端用户操作界面和后端服务，以及服务使用到的硬件资源之间的关联关系。这个系统有点像CMDB（配置管理数据库），但是比CMDB要大得多，是以用户端的功能来做索引的。然后，把后端的服务、服务的调用关系，以及服务使用到的资源都关联起来做成一个视图。




最近发现容器内存使用率过高问题的一个特点：表打开数过多。
确定方法：执行show open tables查看当前打开数
通过top查看mysql进程当前内存使用情况
执行flush tables，查看进程占用内存是否有下降。
解决方法：
flush tables;
set global table_definition_cache = 2000;
set global table_open_cache = 2000;


MHA MMM MGR
double writer
	用来解决部分写失败的问题
保证redo日志的原子性的机制
	redo log日志写入的单位是512字节，也是磁盘IO的最小单位，所以无所谓数据损坏
redis
200G大表  水平分表
ddl  inplace copy
pt工具如何实现ddl  gh-host

pt-osc  gh-host
instant



1.从OSS服务器上拉取数据库的备份
./ossutil64 -c myconfig cp oss备份文件 /data/nxr
2.解压xbstream包
 xbstream --parallel=10 -xv < 下载的oss备份文件 -C ${temporary_path}
 innobackupex --decompress --parallel=8   /data/DBbackup/20190411/base_20190411
3.应用日志 
 innobackupex --apply-log /data/DBbackup/20190411/base_20190411
4.删除数据库原来的数据和日志
 rm -rf data/
 rm ulog/*
 rm rlog/*
5.恢复数据
  innobackupex --defaults-file=/data/mysql/db_1008611_sc/conf/1008611_sc.cnf --copy-back /data/DBbackup/20190411/base_20190411




双中心同步链路搭建
洛阳 --->  淮安

主库A  和 备库 B

方案一：
备库B
1. set sql_log_bin=off
2. 执行语句
3. set sql_log_bin=on;

方案二：
主库A     
1. stop slave;
备库B     
1. 执行语句
2. 查出语句的GTID   show master status; show binlog events in 'mysql-bin.000001';   
主库：
set GTID_NEXT="server_uuid_of_Y:gno";
begin;
commit;
set gtid_next=automatic;
start slave;

分公司纳管需求文档：https://shimo.im/docs/3xqT38yKkY3HvqJ9




read_only 设置

	session 1                                     session 2
	begin;
	insert into t values (1,'nxr'); (成功) 
												  set global read_only = 1;
	insert inot t values(2, 'jsm'); (失败)
	commit; (失败，并且事务自动回滚)



	delete from t 
												 set global read_only = 1; (卡住，需要等待锁释放)
read_only对已存在的事务，也是立即生效的吗？，也不能提交吗，



insert ... select ..语句  会锁住源表上所有行
pt-archiver


select * from t where c>10 and c<20 order by a;

nested-list-to-flat-list   https://djangocentral.com/nested-list-to-flat-list/
def flatten(li):
	return sum(([x] if not isinstance(x, list) else flatten(x) for x in li), [])






实例自动发现：
1、每天自动扫描发现已录入主机上的数据库的实例信息,并自动录入实例信息，包括数据库信息。
2、添加主机信息后自动发现数据库实例新并录入。返回发现结果（成功：发现xx个实例，实名、端口；失败：失败原因）
3、实例自动发现记录查看功能。可查看自动发现的历史记录（xxx、xxx、xxxx）和发现结果，可以搜索、过滤等功能，历史记录中可以按照执行时间，类型等字段排序查看
4、增加手动发现实例按钮在主机列表页的左上方，点击按钮后，返回发现结果（成功：发现xx个实例，实名、端口  失败：失败原因）



容器cmdb成本中心不准确，如何确保容器的成本中心好docker-db对应的工程成本中心保持一致，或者通过巡检修改为一致

oracle执行脚本

1) sqlplus / as sysdba
2) ALTER SESSION SET CURRENT_SCHEMA = BOMCBP;

XtraBackup 备份原理
http://mysql.taobao.org/monthly/2016/03/07/

关于长事务/大事务的监控
1、活跃时间最长的事务
select * from information_schema.innodb_trx order by trx_started asc limit 1

2、等待时间最长的事务
select * from sys.innodb_lock_waits order by wait_age_secs desc limit 1

3、大事务
select * from information_schema.innodb_trx where
	trx_lock_structs >= 5 or
	trx_rows_locked >= 100 or
	trx_rows_modified >= 100 or
	time_to_sec(timediff(now(), trx_started)) > 100;

4、空事务
select  
        concat('kill ',l.id,';') kill_id,
        concat('user:',l.user,';host:',l.host, ';trx_id:',trx_id,';thread_id:',trx_mysql_thread_id,';state:',l.state,';command:',l.command,';kill ',l.id,';') info   
        from  information_schema.innodb_trx trx, information_schema.processlist l 
        where trx.trx_mysql_thread_id=l.id and  TIMESTAMPDIFF(SECOND,trx_started,now()) >10   
        and  l.command='sleep' and l.user not in ('system user','root','myrobot','inception','operator','replic','repl','tvi_backup','tube');